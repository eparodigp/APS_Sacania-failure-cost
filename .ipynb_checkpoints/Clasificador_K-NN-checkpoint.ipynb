{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('aps_failure_training_set.csv',na_values='na')\n",
    "df_test = pd.read_csv('aps_failure_test_set.csv', na_values='na')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = df_train.drop(columns=['class']).columns.values\n",
    "features = np.empty((1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in feature_columns:\n",
    "    if len(df_train.loc[df_train[feature].notnull()]) > 50000:\n",
    "        features = np.append(features,feature)\n",
    "        \n",
    "features = np.delete(features,0,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[features]=df_train[features].fillna(df_train.median())\n",
    "df_test[features]=df_test[features].fillna(df_test.median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_train target:\n",
      "-1    59000\n",
      " 1     1000\n",
      "Name: target, dtype: int64\n",
      "df_test target:\n",
      "-1    15625\n",
      " 1      375\n",
      "Name: target, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['target'] = df_train['class'].replace ({'neg':-1, 'pos':1})\n",
    "df_test['target'] = df_test['class'].replace ({'neg':-1, 'pos':1})\n",
    "print( 'df_train target:'), print(df_train['target'].value_counts())\n",
    "print( 'df_test target:'), print(df_test['target'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (54000, 145)\n",
      "y_train: (54000,)\n",
      "X_val: (6000, 145)\n",
      "y_val: (6000,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df_train[features]\n",
    "y = df_train['target']\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X,y,test_size=0.1, random_state = 1)\n",
    "print('X_train:', X_train.shape); print('y_train:', y_train.shape)\n",
    "print('X_val:', X_val.shape); print('y_val:', y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def projectData(pcaModel, X, K):\n",
    "    Z = pcaModel.transform(X)[:,:K]\n",
    "    return Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recoverData(pcaModel, Z):\n",
    "    K = Z.shape[1]\n",
    "    X_rec = np.dot(Z, pcaModel.components_[:K,:])\n",
    "    return X_rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "\n",
    "pca = PCA().fit(X_train_scaled)\n",
    "pca_loadings = pca.components_\n",
    "pca_scores_train = projectData(pca,X_train_scaled,60)\n",
    "pca_scores_val = projectData(pca,X_val_scaled,60)\n",
    "X_train_pca = recoverData(pca,pca_scores_train)\n",
    "X_val_pca = recoverData(pca,pca_scores_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(54000, 145)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_pca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "modelo = KNeighborsClassifier(n_neighbors = 5)\n",
    "modelo.fit(X_train_pca, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicciones correctas :  5947\n",
      "Número de muestras     :  6000\n",
      "Exactitud (manual)     :  0.9911666666666666\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "predicciones_val = modelo.predict(X_val_pca)\n",
    "num_predicciones_correctas = (y_val == predicciones_val).sum()\n",
    "num_total_de_muestras = len(y_val)\n",
    "exactitud = num_predicciones_correctas / num_total_de_muestras\n",
    "\n",
    "print ( 'Predicciones correctas : ', num_predicciones_correctas )\n",
    "print ( 'Número de muestras     : ', num_total_de_muestras )\n",
    "print ( 'Exactitud (manual)     : ', exactitud )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicciones correctas :  15796\n",
      "Número de muestras     :  16000\n",
      "Exactitud (manual)     :  0.98725\n",
      "Exactitud (score)      :  0.3619375\n",
      "Exactitud (metrics)    :  0.98725\n"
     ]
    }
   ],
   "source": [
    "X_test = df_test[features]\n",
    "y_test = df_test['target']\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "pca_scores_test = projectData(pca,X_test_scaled,60)\n",
    "X_test_pca = recoverData(pca,pca_scores_test)\n",
    "\n",
    "predicciones_test = modelo.predict(X_test_pca)\n",
    "num_predicciones_correctas = (y_test == predicciones_test).sum()\n",
    "num_total_de_muestras = len(y_test)\n",
    "exactitud = num_predicciones_correctas / num_total_de_muestras\n",
    "\n",
    "print ( 'Predicciones correctas : ', num_predicciones_correctas )\n",
    "print ( 'Número de muestras     : ', num_total_de_muestras )\n",
    "print ( 'Exactitud (manual)     : ', exactitud )\n",
    "print ( 'Exactitud (score)      : ', modelo.score(X_test, y_test) )\n",
    "print ( 'Exactitud (metrics)    : ', metrics.accuracy_score(y_test, predicciones_test) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilidades_val = modelo.predict_proba(X_test_pca)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Cost:  34970 197 66 309 15428\n"
     ]
    }
   ],
   "source": [
    "U_check = 10 #cost that an unnecessary check\n",
    "M_check = 500 # cost of missing a faulty truck\n",
    "\n",
    "FN = ((probabilidades_val < 0.05) & (y_test == 1)).sum()\n",
    "TN = ((probabilidades_val < 0.05) & (y_test == -1)).sum()\n",
    "FP = ((probabilidades_val >= 0.05) & (y_test == -1)).sum()\n",
    "TP = ((probabilidades_val >= 0.05) & (y_test == 1)).sum()\n",
    "\n",
    "Total_Cost = FP*U_check + FN*M_check\n",
    "print('Total Cost: ', Total_Cost, FP,  FN, TP, TN)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
