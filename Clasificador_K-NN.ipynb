{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clasificación por medio del método K-NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('Data/aps_failure_training_set.csv',na_values='na')\n",
    "df_test = pd.read_csv('Data/aps_failure_test_set.csv', na_values='na')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = df_train.drop(columns=['class']).columns.values\n",
    "features = np.empty((1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se eliminarán aquellas columnas que posean menos de 50000 datos (número total de datos de entrenamiento : 60000)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in feature_columns:\n",
    "    if len(df_train.loc[df_train[feature].notnull()]) > 50000:\n",
    "        features = np.append(features,feature)\n",
    "        \n",
    "features = np.delete(features,0,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se completarán los datos faltantes con la mediana."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[features]=df_train[features].fillna(df_train.median())\n",
    "df_test[features]=df_test[features].fillna(df_test.median())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se procederá a reemplazar la clase {neg, pos} por {-1, 1} respectivamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_train target:\n",
      "-1    59000\n",
      " 1     1000\n",
      "Name: target, dtype: int64\n",
      "df_test target:\n",
      "-1    15625\n",
      " 1      375\n",
      "Name: target, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['target'] = df_train['class'].replace ({'neg':-1, 'pos':1})\n",
    "df_test['target'] = df_test['class'].replace ({'neg':-1, 'pos':1})\n",
    "print( 'df_train target:'), print(df_train['target'].value_counts())\n",
    "print( 'df_test target:'), print(df_test['target'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se separará un grupo de validación dentro del conjunto de entrenamiento. Se utilizirá un valor de random_state = 1 para mantener uniformidad en las diferentes pruebas que se realicen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (54000, 145)\n",
      "y_train: (54000,)\n",
      "X_val: (6000, 145)\n",
      "y_val: (6000,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df_train[features]\n",
    "y = df_train['target']\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X,y,test_size=0.1, random_state = 1)\n",
    "print('X_train:', X_train.shape); print('y_train:', y_train.shape)\n",
    "print('X_val:', X_val.shape); print('y_val:', y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def projectData(pcaModel, X, K):\n",
    "    Z = pcaModel.transform(X)[:,:K]\n",
    "    return Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recoverData(pcaModel, Z):\n",
    "    K = Z.shape[1]\n",
    "    X_rec = np.dot(Z, pcaModel.components_[:K,:])\n",
    "    return X_rec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se procederá a realizar una reducción de dimensionalidad usando el método PCA. Se escogieron los primeros 60 componentes principales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "scaler = StandardScaler().fit(X)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "\n",
    "pca = PCA().fit(X_train_scaled)\n",
    "pca_loadings = pca.components_\n",
    "pca_scores_train = projectData(pca,X_train_scaled,60)\n",
    "pca_scores_val = projectData(pca,X_val_scaled,60)\n",
    "X_train_pca = recoverData(pca,pca_scores_train)\n",
    "X_val_pca = recoverData(pca,pca_scores_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(54000, 145)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_pca.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se entrena un modelo K-NN con los datos con dimensionalidad reducida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "modelo = KNeighborsClassifier(n_neighbors = 5)\n",
    "modelo.fit(X_train_pca, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se define la función de costo a utilizar para mejorar el modelo. Se decidió variar el umbral de clasificación con el objetivo de disminuir la cantidad de falsos negativos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Costo_total(probabilidades, y):\n",
    "    U_check = 10 #cost that an unnecessary check\n",
    "    M_check = 500 # cost of missing a faulty truck\n",
    "\n",
    "    FN = ((probabilidades < 0.05) & (y == 1)).sum()\n",
    "    TN = ((probabilidades < 0.05) & (y == -1)).sum()\n",
    "    FP = ((probabilidades >= 0.05) & (y == -1)).sum()\n",
    "    TP = ((probabilidades >= 0.05) & (y == 1)).sum()\n",
    "\n",
    "    Costo_total = FP*U_check + FN*M_check\n",
    "    print('Costo total: ', Costo_total, FP,  FN, TP, TN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se analiza el costo que se produce en el conjunto de validación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Costo total:  6920 92 12 96 5800\n"
     ]
    }
   ],
   "source": [
    "probabilidades_val = modelo.predict_proba(X_val_pca)[:,1]\n",
    "Costo_total(probabilidades_val,y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se obtiene la función de costo en el conjunto de prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Costo total:  38700 220 73 302 15405\n"
     ]
    }
   ],
   "source": [
    "X_test = df_test[features]\n",
    "y_test = df_test['target']\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "pca_scores_test = projectData(pca,X_test_scaled,60)\n",
    "X_test_pca = recoverData(pca,pca_scores_test)\n",
    "\n",
    "probabilidades_test = modelo.predict_proba(X_test_pca)[:,1]\n",
    "Costo_total(probabilidades_test,y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
